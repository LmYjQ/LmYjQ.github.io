---
layout:     post
title:      MIR
subtitle:   Music Information Retrieval
date:       2019-03-22
author:     LmYjQ
header-img: img/post-bg-BJJ.jpg
catalog: true
tags:
    - MIR
    - Deep Learning
---

> 译自 [《A Tutorial on Deep Learning for Music Information Retrieval》](https://arxiv.org/pdf/1709.04396.pdf)

### 目录

- 1. 动机（略）
- 2. 深度学习基础
- 3. MIR任务介绍
- 4. 核心模块
- 5. 辅助模块
- 6. 总结


### 2. 深度学习基础

> **BP+SGD求解神经网络；CNN提取特征，LSTM针对序列数据；Relu激活函数**

#### 2.1 深度学习和"传统"方法对比
传统： 输入->特征提取（MFCC）->分类器->结果
深度学习：输入->很多很多层->结果
用“很多很多层”代替“特征提取（MFCC）+分类器”

#### 2.2 网络如何设计&训练
设计：网络结构长什么样子，由超参数决定（hyperparameters），训练过程中不变
损失函数：定义”理想“和”现实“的差距
训练：将数据喂给定义好网络结构和损失函数的神经网络学习，学习过程中参数（weight）不停的变化，直到收敛
梯度：学习过程中需要走的路
学习率：每一步走多大。有一系列动态调节的机制，adam，rmsprop，adagrad，momentum等
激活函数：每一个神经元输入与输出的关系，产生非线性

#### 2.3 数据量小怎么办
数据增强（data augmentation）:在不破坏原始数据的前提下增加加噪声，当作新的样本
迁移学习（transfer learning）:用其他任务训练好的网络当作特征提取器，前提假设是两个任务的数据有相似性
随机网络:随机初始化的CNN可以达到不错的特征提取效果（惊呆🤯了）

### 3. MUSIC INFORMATION RETRIEVAL

#### 3.1 MIR任务（MIR都做什么事）
不是所有问题都能只靠音频信号解决，分类/标签等信息很有用。
关注两个维度
> 1.（label的）主观度: 音高/调性/节奏/和声是客观的；风格，情绪是主观的
> 2. 时间跨度: 音高/和声只要很短的片段就可以判断；情绪/调性需要比较长的旋律才能判断

#### 3.2 音频信号表达
二维：时间域+频率域
STFT(short-time fourier transform):
Mel频谱:
Constant-Q Transform (CQT):
Chromagram:

### 4. 用于MIR的深度网络

